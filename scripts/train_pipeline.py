"""
LabGuardian YOLOv8-OBB å®Œæ•´è®­ç»ƒç®¡çº¿
=============================================

æœ¬è„šæœ¬è¦†ç›–ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹:
  Step 1: æ•°æ®é›†æ ¡éªŒä¸é¢„å¤„ç†
  Step 2: æ•°æ®å¢å¼ºç­–ç•¥é…ç½®
  Step 3: æ¨¡å‹è®­ç»ƒ (YOLOv8-OBB)
  Step 4: è®­ç»ƒç»“æœå¯è§†åŒ–ä¸è¯„ä¼°
  Step 5: æ¨¡å‹å¯¼å‡º (OpenVINO)

ç”¨æ³•:
    # å®Œæ•´æµç¨‹
    python scripts/train_pipeline.py

    # åªè®­ç»ƒ
    python scripts/train_pipeline.py --skip-check

    # å°è§„æ¨¡è¯•è·‘ (éªŒè¯ç¯å¢ƒ)
    python scripts/train_pipeline.py --dry-run

    # æ¢å¤ä¸­æ–­çš„è®­ç»ƒ
    python scripts/train_pipeline.py --resume runs/obb/lab_guardian_v3/weights/last.pt

ä»€ä¹ˆæ˜¯ Jupyter Notebook?
------------------------
Jupyter Notebook (.ipynb) æ˜¯ä¸€ç§äº¤äº’å¼æ–‡æ¡£ï¼Œå¯ä»¥æŠŠä»£ç ã€è¿è¡Œç»“æœã€
æ–‡å­—è¯´æ˜æ··åœ¨ä¸€èµ·ã€‚ä½ å¯ä»¥ä¸€ä¸ªå•å…ƒæ ¼(cell)ä¸€ä¸ªå•å…ƒæ ¼åœ°è¿è¡Œä»£ç ï¼Œ
ç«‹åˆ»çœ‹åˆ°è¾“å‡ºç»“æœï¼Œéå¸¸é€‚åˆè°ƒè¯•å’Œå­¦ä¹ ã€‚

åœ¨ VS Code ä¸­ä½¿ç”¨ Jupyter:
  1. å®‰è£… "Jupyter" æ‰©å±• (å¾®è½¯å®˜æ–¹)
  2. Ctrl+Shift+P â†’ "Create: New Jupyter Notebook"
  3. æŠŠæœ¬è„šæœ¬çš„æ¯ä¸ª STEP å¤åˆ¶åˆ°ä¸€ä¸ª cell é‡Œè¿è¡Œå³å¯

æˆ–è€…ç›´æ¥è¿è¡Œæœ¬ .py è„šæœ¬ï¼Œæ•ˆæœä¸€æ ·ã€‚
"""

import os
import sys
import shutil
import argparse
from pathlib import Path
from collections import Counter
from datetime import datetime

# ============================================================
# è·¯å¾„è®¾ç½®
# ============================================================

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parent.parent
DATASET_DIR = PROJECT_ROOT / "dataset"
MODELS_DIR = PROJECT_ROOT / "models"

# ç±»åˆ«å®šä¹‰ â€” å¿…é¡»ä¸ data.yaml å’Œ config.py å®Œå…¨ä¸€è‡´
CLASS_NAMES = [
    "CAPACITOR",    # 0: ç”µå®¹
    "DIODE",        # 1: äºŒæç®¡
    "LED",          # 2: å‘å…‰äºŒæç®¡
    "RESISTOR",     # 3: ç”µé˜»
    "Push_Button",  # 4: æŒ‰é’®
    "Wire",         # 5: å¯¼çº¿
]


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  STEP 1: æ•°æ®é›†æ ¡éªŒä¸é¢„å¤„ç†                              â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_dataset(dataset_dir: Path, fix: bool = False) -> dict:
    """æ ¡éªŒæ•°æ®é›†å®Œæ•´æ€§ï¼Œè¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚

    æ£€æŸ¥é¡¹:
      - æ¯å¼ å›¾ç‰‡æ˜¯å¦æœ‰å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
      - æ ‡ç­¾æ ¼å¼æ˜¯å¦æ­£ç¡® (OBB: class x1 y1 x2 y2 x3 y3 x4 y4)
      - ç±»åˆ« ID æ˜¯å¦åœ¨åˆæ³•èŒƒå›´å†…
      - åæ ‡å€¼æ˜¯å¦å½’ä¸€åŒ–åˆ° [0, 1]
    """
    stats = {
        "total_images": 0,
        "total_labels": 0,
        "missing_labels": [],
        "orphan_labels": [],
        "format_errors": [],
        "class_distribution": Counter(),
        "bbox_count": 0,
        "needs_obb_fix": 0,   # xywh æ ¼å¼éœ€è½¬ä¸º OBB
    }

    for split in ["train", "val", "test"]:
        img_dir = dataset_dir / split / "images"
        lbl_dir = dataset_dir / split / "labels"

        if not img_dir.exists():
            continue

        image_files = set()
        for ext in ("*.jpg", "*.jpeg", "*.png", "*.bmp"):
            image_files.update(f.stem for f in img_dir.glob(ext))

        label_files = set(f.stem for f in lbl_dir.glob("*.txt")) if lbl_dir.exists() else set()

        stats["total_images"] += len(image_files)
        stats["total_labels"] += len(label_files)

        # ç¼ºå¤±æ ‡ç­¾
        for img in image_files - label_files:
            stats["missing_labels"].append(f"{split}/{img}")

        # å­¤ç«‹æ ‡ç­¾
        for lbl in label_files - image_files:
            stats["orphan_labels"].append(f"{split}/{lbl}")

        # é€æ–‡ä»¶æ£€æŸ¥æ ‡ç­¾æ ¼å¼
        for lbl_file in sorted(lbl_dir.glob("*.txt")) if lbl_dir.exists() else []:
            lines = lbl_file.read_text().strip().splitlines()
            for i, line in enumerate(lines):
                parts = line.strip().split()
                if not parts:
                    continue

                try:
                    cls_id = int(parts[0])
                    coords = [float(x) for x in parts[1:]]
                except ValueError:
                    stats["format_errors"].append(
                        f"{split}/{lbl_file.name}:{i+1} è§£æå¤±è´¥")
                    continue

                # ç±»åˆ«æ£€æŸ¥
                if cls_id < 0 or cls_id >= len(CLASS_NAMES):
                    stats["format_errors"].append(
                        f"{split}/{lbl_file.name}:{i+1} ç±»åˆ« {cls_id} è¶…å‡ºèŒƒå›´ [0,{len(CLASS_NAMES)-1}]")

                # æ ¼å¼æ£€æŸ¥
                if len(coords) == 4:
                    # xywh æ ¼å¼ â†’ éœ€è¦è½¬ä¸º OBB
                    stats["needs_obb_fix"] += 1
                elif len(coords) == 8:
                    # OBB å››ç‚¹æ ¼å¼ â†’ æ­£ç¡®
                    pass
                else:
                    stats["format_errors"].append(
                        f"{split}/{lbl_file.name}:{i+1} "
                        f"åæ ‡æ•°é‡ {len(coords)} ä¸æ˜¯ 4(xywh) ä¹Ÿä¸æ˜¯ 8(OBB)")
                    continue

                # åæ ‡èŒƒå›´æ£€æŸ¥
                for v in coords:
                    if v < -0.01 or v > 1.01:
                        stats["format_errors"].append(
                            f"{split}/{lbl_file.name}:{i+1} åæ ‡ {v:.4f} è¶…å‡º [0,1]")
                        break

                stats["class_distribution"][CLASS_NAMES[cls_id]] += 1
                stats["bbox_count"] += 1

    # æ‰“å°æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ•°æ®é›†æ ¡éªŒæŠ¥å‘Š")
    print("=" * 60)
    print(f"  å›¾ç‰‡: {stats['total_images']}  æ ‡ç­¾: {stats['total_labels']}")
    print(f"  æ ‡æ³¨æ¡†: {stats['bbox_count']}")

    if stats["class_distribution"]:
        print("\n  ç±»åˆ«åˆ†å¸ƒ:")
        for cls, cnt in stats["class_distribution"].most_common():
            bar = "â–ˆ" * min(cnt, 50)
            print(f"    {cls:15s} {cnt:5d}  {bar}")

    if stats["missing_labels"]:
        print(f"\n  âš ï¸ ç¼ºå¤±æ ‡ç­¾: {len(stats['missing_labels'])} å¼ å›¾ç‰‡æ— æ ‡ç­¾")
        for m in stats["missing_labels"][:5]:
            print(f"    - {m}")

    if stats["needs_obb_fix"] > 0:
        print(f"\n  âš ï¸ æœ‰ {stats['needs_obb_fix']} ä¸ªæ ‡æ³¨æ˜¯ xywh æ ¼å¼ï¼Œéœ€è¦è½¬ä¸º OBB å››ç‚¹æ ¼å¼")
        if fix:
            print("  â†’ æ­£åœ¨è‡ªåŠ¨ä¿®å¤...")
            _fix_xywh_to_obb(dataset_dir)

    if stats["format_errors"]:
        print(f"\n  âŒ æ ¼å¼é”™è¯¯: {len(stats['format_errors'])}")
        for e in stats["format_errors"][:10]:
            print(f"    - {e}")

    if not stats["format_errors"] and not stats["missing_labels"]:
        print("\n  âœ… æ•°æ®é›†æ ¡éªŒé€šè¿‡ï¼")

    print("=" * 60)
    return stats


def _fix_xywh_to_obb(dataset_dir: Path):
    """å°† xywh æ ¼å¼è‡ªåŠ¨è½¬æ¢ä¸º OBB å››ç‚¹æ ¼å¼ã€‚"""
    fixed = 0
    for split in ["train", "val", "test"]:
        lbl_dir = dataset_dir / split / "labels"
        if not lbl_dir.exists():
            continue

        for lbl_file in lbl_dir.glob("*.txt"):
            lines = lbl_file.read_text().strip().splitlines()
            new_lines = []
            modified = False

            for line in lines:
                parts = line.strip().split()
                if len(parts) == 5:
                    cls = int(parts[0])
                    x, y, w, h = [float(v) for v in parts[1:]]
                    # xywh â†’ å››è§’åæ ‡
                    x1, y1 = x - w/2, y - h/2
                    x2, y2 = x + w/2, y - h/2
                    x3, y3 = x + w/2, y + h/2
                    x4, y4 = x - w/2, y + h/2
                    new_lines.append(
                        f"{cls} {x1:.6f} {y1:.6f} {x2:.6f} {y2:.6f} "
                        f"{x3:.6f} {y3:.6f} {x4:.6f} {y4:.6f}")
                    modified = True
                else:
                    new_lines.append(line.strip())

            if modified:
                lbl_file.write_text("\n".join(new_lines) + "\n")
                fixed += 1

    print(f"  â†’ å·²ä¿®å¤ {fixed} ä¸ªæ–‡ä»¶")


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  STEP 2: ç”Ÿæˆ data.yaml                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_data_yaml(dataset_dir: Path) -> Path:
    """æ ¹æ®å®é™…ç›®å½•ç»“æ„ç”Ÿæˆ/æ›´æ–° data.yamlã€‚

    data.yaml æ˜¯ YOLO è®­ç»ƒçš„æ•°æ®é›†æè¿°æ–‡ä»¶ï¼Œå‘Šè¯‰æ¨¡å‹:
      - è®­ç»ƒé›†/éªŒè¯é›†çš„å›¾ç‰‡åœ¨å“ª
      - ä¸€å…±æœ‰å¤šå°‘ä¸ªç±»åˆ«
      - æ¯ä¸ªç±»åˆ«å«ä»€ä¹ˆåå­—
    """
    yaml_path = dataset_dir / "data.yaml"

    # è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„ split
    splits = {}
    for split in ["train", "val", "test"]:
        img_dir = dataset_dir / split / "images"
        if img_dir.exists() and any(img_dir.iterdir()):
            splits[split] = f"{split}/images"

    if "train" not in splits:
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°è®­ç»ƒé›†! è¯·å°†å›¾ç‰‡æ”¾åˆ° {dataset_dir}/train/images/")

    # å¦‚æœæ²¡æœ‰å•ç‹¬çš„ valï¼Œç”¨ train ä»£æ›¿ï¼ˆä¸æ¨èï¼Œä½†å¯å…ˆè·‘é€šï¼‰
    if "val" not in splits:
        print("  âš ï¸ æœªæ‰¾åˆ°éªŒè¯é›† (val/)ï¼Œå°†ä½¿ç”¨ train ä»£æ›¿ã€‚")
        print("  â†’ å»ºè®®: æ‹ç…§æ—¶ç•™å‡º 10-20% çš„å›¾ç‰‡æ”¾åˆ° val/images/ å’Œ val/labels/")
        splits["val"] = splits["train"]

    content = f"""# LabGuardian æ•°æ®é›†é…ç½®
# è‡ªåŠ¨ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M')}

path: {dataset_dir.as_posix()}
train: {splits['train']}
val: {splits['val']}
"""
    if "test" in splits:
        content += f"test: {splits['test']}\n"

    content += f"""
nc: {len(CLASS_NAMES)}
names:
"""
    for name in CLASS_NAMES:
        content += f"- {name}\n"

    yaml_path.write_text(content, encoding="utf-8")
    print(f"  âœ… data.yaml å·²ç”Ÿæˆ: {yaml_path}")
    return yaml_path


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  STEP 3: è®­ç»ƒæ¨¡å‹                                       â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def train_model(
    data_yaml: Path,
    epochs: int = 200,
    imgsz: int = 960,
    batch: int = 8,
    device: str = "0",
    model_size: str = "s",
    resume: str = None,
    dry_run: bool = False,
    project_name: str = "lab_guardian_v3",
):
    """å¯åŠ¨ YOLOv8-OBB è®­ç»ƒã€‚

    å…³é”®æ¦‚å¿µè§£é‡Š
    ------------
    epochs (è½®æ¬¡):
        æ•´ä¸ªæ•°æ®é›†è¢«å®Œæ•´è®­ç»ƒä¸€éå«ä¸€ä¸ª epochã€‚
        200 epochs = æ‰€æœ‰å›¾ç‰‡è¢«çœ‹ 200 éã€‚
        ä¸€èˆ¬ 100-300 å³å¯ï¼Œé…åˆ early stoppingã€‚

    imgsz (è¾“å…¥åˆ†è¾¨ç‡):
        è®­ç»ƒæ—¶å›¾ç‰‡è¢«ç¼©æ”¾åˆ°çš„å°ºå¯¸ã€‚è¶Šå¤§è¶Šç²¾ç¡®ä½†è¶Šæ…¢è¶Šè€—æ˜¾å­˜ã€‚
        - 640: é€Ÿåº¦å¿«ï¼Œé€‚åˆè°ƒè¯•
        - 960: æ¨èï¼Œé¢åŒ…æ¿å…ƒä»¶è¾ƒå°éœ€è¦é«˜åˆ†è¾¨ç‡
        - 1280: ç²¾åº¦æœ€é«˜ï¼Œéœ€è¦å¤§æ˜¾å­˜

    batch (æ‰¹å¤§å°):
        æ¯æ¬¡é€å…¥ GPU çš„å›¾ç‰‡æ•°é‡ã€‚å—æ˜¾å­˜é™åˆ¶:
        - 4: 4GB æ˜¾å­˜
        - 8: 8GB æ˜¾å­˜ (æ¨è)
        - 16: 16GB+ æ˜¾å­˜

    model_size (æ¨¡å‹å°ºå¯¸):
        - "n" (nano): æœ€å¿«ï¼Œç²¾åº¦æœ€ä½ï¼Œé€‚åˆè°ƒè¯•
        - "s" (small): é€Ÿåº¦/ç²¾åº¦å¹³è¡¡ (æ¨è)
        - "m" (medium): æ›´ç²¾ç¡®ä½†æ›´æ…¢
        - "l" (large): æœ€ç²¾ç¡®ï¼Œéœ€è¦å¤§æ˜¾å­˜

    patience (æ—©åœ):
        å¦‚æœéªŒè¯æŒ‡æ ‡è¿ç»­ N ä¸ª epoch æ²¡æœ‰æå‡ï¼Œè‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚
        é˜²æ­¢è¿‡æ‹Ÿåˆï¼ˆæ¨¡å‹è®°ä½äº†è®­ç»ƒå›¾ç‰‡ä½†ä¸èƒ½æ³›åŒ–åˆ°æ–°å›¾ç‰‡ï¼‰ã€‚

    OBB vs æ™®é€šæ£€æµ‹:
        OBB (Oriented Bounding Box) = æ—‹è½¬è¾¹ç•Œæ¡†
        æ™®é€šæ£€æµ‹åªèƒ½ç”»æ°´å¹³çŸ©å½¢ï¼ŒOBB å¯ä»¥ç”»ä»»æ„è§’åº¦çš„çŸ©å½¢ã€‚
        é¢åŒ…æ¿ä¸Šçš„å…ƒä»¶å¯èƒ½æ–œç€æ”¾ï¼Œæ‰€ä»¥ç”¨ OBB æ›´å‡†ç¡®ï¼Œ
        è€Œä¸” OBB çš„çŸ­è¾¹ä¸­ç‚¹å¤©ç„¶å°±æ˜¯å…ƒä»¶å¼•è„šä½ç½®ï¼

    æ•°æ®å¢å¼º (Augmentation):
        è®­ç»ƒæ—¶è‡ªåŠ¨å¯¹å›¾ç‰‡åšéšæœºå˜æ¢ï¼ˆç¿»è½¬ã€æ—‹è½¬ã€è‰²å½©è°ƒæ•´ç­‰ï¼‰ï¼Œ
        è®©æ¨¡å‹è§åˆ°æ›´å¤šå˜åŒ–ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚YOLO å†…ç½®äº†å¤§é‡å¢å¼ºç­–ç•¥ã€‚
    """
    from ultralytics import YOLO

    # é€‰æ‹©åŸºç¡€æƒé‡
    weights = f"yolov8{model_size}-obb.pt"
    if resume:
        weights = resume
        print(f"  ğŸ”„ æ¢å¤è®­ç»ƒ: {resume}")
    else:
        print(f"  ğŸ“¦ åŸºç¡€æƒé‡: {weights}")

    print(f"  ğŸ“ æ•°æ®é›†:   {data_yaml}")
    print(f"  ğŸ”¢ Epochs:   {epochs}")
    print(f"  ğŸ“ ImgSz:    {imgsz}")
    print(f"  ğŸ“Š Batch:    {batch}")
    print(f"  ğŸ’» Device:   {device}")

    if dry_run:
        print("\n  ğŸ§ª Dry-run æ¨¡å¼: åªè®­ç»ƒ 3 ä¸ª epoch éªŒè¯ç¯å¢ƒ")
        epochs = 3
        batch = 2

    model = YOLO(weights)

    # ---- å¼€å§‹è®­ç»ƒ ----
    results = model.train(
        data=str(data_yaml),
        epochs=epochs,
        imgsz=imgsz,
        batch=batch,
        device=device,
        name=project_name,
        exist_ok=True,          # è¦†ç›–åŒåå®éªŒ
        patience=50,            # 50 epoch æ— æå‡åˆ™æ—©åœ
        save_period=20,         # æ¯ 20 epoch ä¿å­˜ä¸€æ¬¡ checkpoint

        # ---- æ•°æ®å¢å¼ºå‚æ•° ----
        # è¿™äº›æ˜¯é¢åŒ…æ¿åœºæ™¯ä¼˜åŒ–è¿‡çš„å€¼
        degrees=15.0,           # éšæœºæ—‹è½¬ Â±15Â° (å…ƒä»¶å¯èƒ½ç¨æœ‰å€¾æ–œ)
        translate=0.1,          # éšæœºå¹³ç§» 10%
        scale=0.3,              # éšæœºç¼©æ”¾ Â±30% (æ¨¡æ‹Ÿä¸åŒæ‹æ‘„è·ç¦»)
        shear=2.0,              # å¾®å°å‰ªåˆ‡å˜æ¢
        perspective=0.0005,     # è½»å¾®é€è§†å˜æ¢ (æ¨¡æ‹Ÿä¸åŒæ‹æ‘„è§’åº¦)
        flipud=0.0,             # ç¦æ­¢ä¸Šä¸‹ç¿»è½¬ (é¢åŒ…æ¿æœ‰ä¸Šä¸‹æ–¹å‘)
        fliplr=0.5,             # 50% æ¦‚ç‡å·¦å³ç¿»è½¬
        mosaic=1.0,             # Mosaic å¢å¼º (4 å›¾æ‹¼æ¥)
        mixup=0.1,              # 10% MixUp (ä¸¤å›¾æ··åˆ)
        hsv_h=0.015,            # è‰²è°ƒå¾®è°ƒ (ä¸åŒç¯å…‰)
        hsv_s=0.5,              # é¥±å’Œåº¦å˜åŒ–
        hsv_v=0.4,              # äº®åº¦å˜åŒ– (æ¨¡æ‹Ÿä¸åŒå…‰ç…§)
        erasing=0.2,            # 20% éšæœºæ“¦é™¤ (æ¨¡æ‹Ÿé®æŒ¡)

        # ---- ä¼˜åŒ–å™¨å‚æ•° ----
        optimizer="auto",       # è‡ªåŠ¨é€‰æ‹© (SGD/AdamW)
        lr0=0.01,               # åˆå§‹å­¦ä¹ ç‡
        lrf=0.01,               # æœ€ç»ˆå­¦ä¹ ç‡è¡°å‡æ¯”
        warmup_epochs=5,        # é¢„çƒ­è½®æ¬¡

        # ---- å…¶ä»– ----
        workers=4,              # æ•°æ®åŠ è½½çº¿ç¨‹
        seed=42,                # éšæœºç§å­ (ä¿è¯å¯å¤ç°)
        verbose=True,
    )

    # è®­ç»ƒç»“æœè·¯å¾„
    run_dir = Path(f"runs/obb/{project_name}")
    best_pt = run_dir / "weights" / "best.pt"

    print("\n" + "=" * 60)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"  æœ€ä½³æ¨¡å‹: {best_pt}")
    print(f"  è®­ç»ƒæ—¥å¿—: {run_dir}")
    print(f"  ä¸‹ä¸€æ­¥:   python scripts/train_pipeline.py --evaluate {best_pt}")
    print("=" * 60)

    return best_pt


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  STEP 4: è¯„ä¼°æ¨¡å‹                                       â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def evaluate_model(model_path: Path, data_yaml: Path, imgsz: int = 960):
    """åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œè¾“å‡ºå…³é”®æŒ‡æ ‡ã€‚

    å…³é”®æŒ‡æ ‡è§£é‡Š
    ------------
    mAP50 (mean Average Precision @ IoU=0.5):
        æ‰€æœ‰ç±»åˆ«åœ¨ IoUâ‰¥50% æ—¶çš„å¹³å‡ç²¾åº¦ã€‚
        é€šä¿—è¯´: æ¨¡å‹æ£€æµ‹åˆ°çš„æ¡†å’ŒçœŸå®æ¡†é‡å è¶…è¿‡ä¸€åŠå°±ç®—å¯¹ã€‚
        - > 0.7: å¯ç”¨
        - > 0.85: è‰¯å¥½
        - > 0.95: ä¼˜ç§€

    mAP50-95:
        åœ¨ IoU ä» 0.5 åˆ° 0.95 (æ­¥é•¿ 0.05) èŒƒå›´å†…å–å¹³å‡ã€‚
        æ¯” mAP50 æ›´ä¸¥æ ¼ï¼Œæ˜¯ç›®æ ‡æ£€æµ‹çš„æ ‡å‡†æŒ‡æ ‡ã€‚

    Precision (ç²¾ç¡®ç‡):
        æ¨¡å‹è¯´"è¿™æ˜¯ç”µé˜»"çš„æ—¶å€™ï¼ŒçœŸçš„æ˜¯ç”µé˜»çš„æ¯”ä¾‹ã€‚
        ç²¾ç¡®ç‡ä½ = è¯¯æŠ¥å¤š (æŠŠä¸æ˜¯å…ƒä»¶çš„ä¸œè¥¿æ£€æˆå…ƒä»¶)ã€‚

    Recall (å¬å›ç‡):
        æ‰€æœ‰çœŸå®ç”µé˜»ä¸­ï¼Œè¢«æ¨¡å‹æ‰¾åˆ°çš„æ¯”ä¾‹ã€‚
        å¬å›ç‡ä½ = æ¼æ£€å¤š (æœ‰å…ƒä»¶ä½†æ²¡æ£€æµ‹åˆ°)ã€‚

    æ¯ç±» AP:
        å„ç±»åˆ«å•ç‹¬çš„ç²¾åº¦ã€‚å¯ä»¥çœ‹å‡ºå“ªç±»æ£€æµ‹å¥½ã€å“ªç±»éœ€è¦æ›´å¤šæ•°æ®ã€‚
    """
    from ultralytics import YOLO

    print(f"\nğŸ“Š è¯„ä¼°æ¨¡å‹: {model_path}")
    model = YOLO(str(model_path))

    metrics = model.val(
        data=str(data_yaml),
        imgsz=imgsz,
        batch=8,
        verbose=True,
    )

    print("\n" + "=" * 60)
    print("ğŸ“Š è¯„ä¼°ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"  mAP50:    {metrics.box.map50:.4f}")
    print(f"  mAP50-95: {metrics.box.map:.4f}")

    # æ¯ç±»ç²¾åº¦
    if hasattr(metrics.box, 'ap_class_index'):
        print("\n  æ¯ç±» AP50:")
        for i, cls_idx in enumerate(metrics.box.ap_class_index):
            cls_name = CLASS_NAMES[int(cls_idx)] if int(cls_idx) < len(CLASS_NAMES) else f"class_{cls_idx}"
            ap = metrics.box.ap50[i]
            bar = "â–ˆ" * int(ap * 30)
            print(f"    {cls_name:15s} {ap:.3f}  {bar}")

    print("=" * 60)
    return metrics


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  STEP 5: å¯¼å‡ºæ¨¡å‹ (OpenVINO)                            â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def export_model(model_path: Path, format: str = "openvino", imgsz: int = 960):
    """å°†è®­ç»ƒå¥½çš„æ¨¡å‹å¯¼å‡ºä¸ºéƒ¨ç½²æ ¼å¼ã€‚

    OpenVINO å¯¼å‡ºè¯´æ˜
    -----------------
    æ¯”èµ›å¹³å°æ˜¯ Intel DK-2500 (Core Ultra 5 225U)ï¼Œè‡ªå¸¦ NPUã€‚
    OpenVINO å¯ä»¥è®©æ¨¡å‹åœ¨ Intel CPU/GPU/NPU ä¸Šé«˜æ•ˆæ¨ç†ã€‚

    å¯¼å‡ºåä¼šç”Ÿæˆä¸€ä¸ªç›®å½•ï¼ŒåŒ…å« .xml å’Œ .bin æ–‡ä»¶ï¼Œ
    æ”¾åˆ° models/ ç›®å½•ä¸‹å³å¯è¢« LabGuardian è‡ªåŠ¨åŠ è½½ã€‚
    """
    from ultralytics import YOLO

    print(f"\nğŸ“¦ å¯¼å‡ºæ¨¡å‹: {model_path} â†’ {format}")
    model = YOLO(str(model_path))

    export_path = model.export(
        format=format,
        imgsz=imgsz,
        half=False,     # INT8/FP16 é‡åŒ–åœ¨ OpenVINO ç«¯åšæ›´çµæ´»
    )

    print(f"  âœ… å¯¼å‡ºå®Œæˆ: {export_path}")

    # å¤åˆ¶åˆ° models/ ç›®å½•
    dst = MODELS_DIR / f"lab_guardian_obb_{format}"
    if Path(export_path).is_dir():
        if dst.exists():
            shutil.rmtree(dst)
        shutil.copytree(export_path, dst)
        print(f"  ğŸ“ å·²å¤åˆ¶åˆ°: {dst}")

    return export_path


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  STEP 6: å¿«é€Ÿé¢„æµ‹æµ‹è¯•                                   â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def quick_predict(model_path: Path, image_path: Path, imgsz: int = 960):
    """ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å•å¼ å›¾ç‰‡åšé¢„æµ‹ï¼Œå¯è§†åŒ–ç»“æœã€‚"""
    from ultralytics import YOLO
    import cv2

    print(f"\nğŸ” é¢„æµ‹æµ‹è¯•: {image_path}")
    model = YOLO(str(model_path))

    results = model(
        str(image_path),
        imgsz=imgsz,
        conf=0.25,
        save=True,
        save_txt=True,
    )

    result = results[0]
    n_det = len(result.obb) if result.obb is not None else len(result.boxes) if result.boxes is not None else 0
    print(f"  æ£€æµ‹åˆ° {n_det} ä¸ªå…ƒä»¶")
    print(f"  ç»“æœä¿å­˜åœ¨ runs/obb/predict/")

    return results


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  ä¸»å‡½æ•°                                                  â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="LabGuardian YOLOv8-OBB è®­ç»ƒç®¡çº¿",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument("--dataset", type=str,
                        default=str(DATASET_DIR),
                        help="æ•°æ®é›†ç›®å½•è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=200,
                        help="è®­ç»ƒè½®æ¬¡ (é»˜è®¤ 200)")
    parser.add_argument("--imgsz", type=int, default=960,
                        help="è¾“å…¥åˆ†è¾¨ç‡ (é»˜è®¤ 960)")
    parser.add_argument("--batch", type=int, default=8,
                        help="æ‰¹å¤§å° (é»˜è®¤ 8ï¼Œæ˜¾å­˜ä¸å¤Ÿå°±æ”¹å°)")
    parser.add_argument("--device", type=str, default="0",
                        help="è®¾å¤‡: '0'=GPU, 'cpu'=CPU")
    parser.add_argument("--model-size", type=str, default="s",
                        choices=["n", "s", "m", "l"],
                        help="æ¨¡å‹å°ºå¯¸: n/s/m/l (é»˜è®¤ s)")
    parser.add_argument("--name", type=str, default="lab_guardian_v3",
                        help="å®éªŒåç§°")
    parser.add_argument("--resume", type=str, default=None,
                        help="æ¢å¤è®­ç»ƒçš„ checkpoint è·¯å¾„")
    parser.add_argument("--dry-run", action="store_true",
                        help="å¿«é€Ÿè¯•è·‘ (3 epoch)")
    parser.add_argument("--skip-check", action="store_true",
                        help="è·³è¿‡æ•°æ®é›†æ ¡éªŒ")
    parser.add_argument("--fix-labels", action="store_true",
                        help="è‡ªåŠ¨ä¿®å¤ xywhâ†’OBB æ ¼å¼")
    parser.add_argument("--evaluate", type=str, default=None,
                        help="è¯„ä¼°æŒ‡å®šæ¨¡å‹ (è·³è¿‡è®­ç»ƒ)")
    parser.add_argument("--export", type=str, default=None,
                        help="å¯¼å‡ºæŒ‡å®šæ¨¡å‹ä¸º OpenVINO")
    parser.add_argument("--predict", type=str, default=None,
                        help="ç”¨æ¨¡å‹é¢„æµ‹ä¸€å¼ å›¾ç‰‡")
    parser.add_argument("--predict-model", type=str, default=None,
                        help="é¢„æµ‹ç”¨çš„æ¨¡å‹è·¯å¾„")

    args = parser.parse_args()
    dataset_dir = Path(args.dataset)

    print("=" * 60)
    print("ğŸ”¬ LabGuardian YOLOv8-OBB è®­ç»ƒç®¡çº¿")
    print(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("=" * 60)

    # ---- ä»…è¯„ä¼° ----
    if args.evaluate:
        yaml_path = dataset_dir / "data.yaml"
        if not yaml_path.exists():
            yaml_path = generate_data_yaml(dataset_dir)
        evaluate_model(Path(args.evaluate), yaml_path, args.imgsz)
        return

    # ---- ä»…å¯¼å‡º ----
    if args.export:
        export_model(Path(args.export), "openvino", args.imgsz)
        return

    # ---- ä»…é¢„æµ‹ ----
    if args.predict:
        model = args.predict_model or str(MODELS_DIR / "yolov8n-obb.pt")
        quick_predict(Path(model), Path(args.predict), args.imgsz)
        return

    # ---- å®Œæ•´æµç¨‹ ----

    # Step 1: æ•°æ®é›†æ ¡éªŒ
    if not args.skip_check:
        print("\nğŸ“‹ Step 1: æ•°æ®é›†æ ¡éªŒ")
        stats = check_dataset(dataset_dir, fix=args.fix_labels)
        if stats["total_images"] == 0:
            print("\nâŒ æ•°æ®é›†ä¸ºç©ºï¼è¯·å…ˆå‡†å¤‡æ•°æ®ï¼š")
            print(f"   å›¾ç‰‡æ”¾åˆ°: {dataset_dir}/train/images/")
            print(f"   æ ‡ç­¾æ”¾åˆ°: {dataset_dir}/train/labels/")
            print("   æ ‡ç­¾æ ¼å¼: class_id x1 y1 x2 y2 x3 y3 x4 y4")
            print("   (æ¯è¡Œä¸€ä¸ªæ ‡æ³¨ï¼Œåæ ‡å½’ä¸€åŒ–åˆ° 0-1)")
            return

    # Step 2: ç”Ÿæˆ data.yaml
    print("\nğŸ“ Step 2: ç”Ÿæˆ data.yaml")
    yaml_path = generate_data_yaml(dataset_dir)

    # Step 3: è®­ç»ƒ
    print("\nğŸš€ Step 3: å¼€å§‹è®­ç»ƒ")
    best_pt = train_model(
        data_yaml=yaml_path,
        epochs=args.epochs,
        imgsz=args.imgsz,
        batch=args.batch,
        device=args.device,
        model_size=args.model_size,
        resume=args.resume,
        dry_run=args.dry_run,
        project_name=args.name,
    )

    # Step 4: è¯„ä¼°
    if best_pt and best_pt.exists():
        print("\nğŸ“Š Step 4: è¯„ä¼°æ¨¡å‹")
        evaluate_model(best_pt, yaml_path, args.imgsz)

        # Step 5: å¯¼å‡º
        print("\nğŸ“¦ Step 5: å¯¼å‡º OpenVINO æ ¼å¼")
        try:
            export_model(best_pt, "openvino", args.imgsz)
        except Exception as e:
            print(f"  âš ï¸ å¯¼å‡ºå¤±è´¥: {e}")
            print("  â†’ å¯ä»¥ç¨åæ‰‹åŠ¨æ‰§è¡Œ: python scripts/train_pipeline.py --export <model_path>")


if __name__ == "__main__":
    main()
