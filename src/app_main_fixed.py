import cv2
import sys
import threading
import time
from datetime import datetime
from queue import Queue
import os
import glob
import numpy as np
import networkx as nx
from tkinter import filedialog, simpledialog # æ–°å¢ simpledialog

# å›¾å½¢ç•Œé¢åº“
import tkinter as tk
from tkinter import ttk, scrolledtext
from PIL import Image, ImageTk

# AI åº“
from ultralytics import YOLO
from optimum.intel.openvino import OVModelForCausalLM
from transformers import AutoTokenizer
from openai import OpenAI # æ–°å¢ OpenAI åº“æ”¯æŒ

# --- Cloud LLM é…ç½® ---
USE_CLOUD_LLM = True # å¼€å¯äº‘ç«¯ AI æ¨¡å¼ (æ›´æ™ºèƒ½ï¼Œæ”¯æŒä¸­æ–‡)

# è¯·åœ¨ä¸‹æ–¹å¡«å…¥æ‚¨çš„ API Key (ä¾‹å¦‚ DeepSeek, Moonshot, Alibaba DashScope ç­‰)
# è¿™é‡Œé¢„è®¾ä¸º DeepSeek çš„é…ç½®ï¼Œå¦‚æœæ‚¨æœ‰å…¶ä»– OpenAI å…¼å®¹çš„ Key ä¹Ÿå¯ä»¥å¡«
CLOUD_API_KEY = "sk-756ee8992b8342a6926bc3b5a90e90a9" # <--- è¯·åœ¨æ­¤å¤„å¡«å…¥æ‚¨çš„ Key
CLOUD_BASE_URL = "https://api.deepseek.com" # æˆ–è€… api.moonshot.cn ç­‰
CLOUD_MODEL_NAME = "deepseek-chat" # æˆ–è€… moonshot-v1-8k, qwen-turbo ç­‰

# --- å¼•å…¥æ–°æ¨¡å— ---
from calibration import board_map
from circuit_logic import CircuitAnalyzer, CircuitComponent, validator
from schematic_viz import SchematicGenerator # æ–°å¢å¯è§†åŒ–å·¥å™¨
analyzer = CircuitAnalyzer()

# --- é…ç½®ä¿®æ­£åŒºåŸŸ ---
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ src ç›®å½•ç»å¯¹è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# 1. åŠ¨æ€æŸ¥æ‰¾ YOLO æ¨¡å‹ (best.pt)
# æˆ‘ä»¬å‡è®¾ runs æ–‡ä»¶å¤¹ä½äº src ç›®å½•ä¸‹
runs_dir = os.path.join(BASE_DIR, 'runs', 'detect')
print(f"Debug: Looking for YOLO models in {runs_dir}")

# æŸ¥æ‰¾ lab_guardian* ä¸‹æ‰€æœ‰çš„ best.pt
candidates = glob.glob(os.path.join(runs_dir, 'lab_guardian*', 'weights', 'best.pt'))

if candidates:
    # ä¼˜å…ˆå¯»æ‰¾åŒ…å« "oneshot" çš„æ¨¡å‹ï¼Œå› ä¸ºè¿™äº›æ˜¯é’ˆå¯¹æ¼”ç¤ºä¼˜åŒ–çš„
    oneshot_candidates = [c for c in candidates if "oneshot" in c]
    if oneshot_candidates:
        YOLO_MODEL_PATH = max(oneshot_candidates, key=os.path.getmtime)
        print(f"Debug: Found Dedicated Demo Model: {YOLO_MODEL_PATH}")
    else:
        # å¦åˆ™æ‰¾é€šç”¨çš„æœ€æ–°çš„
        YOLO_MODEL_PATH = max(candidates, key=os.path.getmtime)
        print(f"Debug: Found YOLO model: {YOLO_MODEL_PATH}")
else:
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä¸€ä¸ªç¡¬ç¼–ç çš„é»˜è®¤è·¯å¾„ (å›é€€)
    print("Debug: No custom model found, attempting default path...")
    YOLO_MODEL_PATH = os.path.join(BASE_DIR, "runs/detect/lab_guardian_v1/weights/best.pt")

# 2. åŠ¨æ€è®¾ç½® LLM æ¨¡å‹è·¯å¾„ (ä½¿ç”¨ç»å¯¹è·¯å¾„è§£å†³ from_pretrained æŠ¥é”™)
LLM_MODEL_PATH = os.path.join(BASE_DIR, "openvino_tinyllama_model")
print(f"Debug: LLM Model Path set to: {LLM_MODEL_PATH}")

# --- ä¸»ç¨‹åºç±» ---
class LabGuardianApp:
    def __init__(self, root):
        self.root = root
        self.root.title("LabGuardian - Intel Embedded AI Assistant")
        self.root.geometry("1400x900")
        
        # æ™ºèƒ½é…ç½®æ£€æŸ¥
        global CLOUD_API_KEY
        if USE_CLOUD_LLM and "placeholder" in CLOUD_API_KEY:
             # å°è¯•å¼¹çª—è¯·æ±‚ Key
             key = simpledialog.askstring("DeepSeek API é…ç½®", 
                                        "æ£€æµ‹åˆ°æ‚¨å¼€å¯äº†äº‘ç«¯ AI æ¨¡å¼ã€‚\nè¯·è¾“å…¥æ‚¨çš„ DeepSeek API Key (sk-...):\n(å¦‚æœä¸è¾“å…¥å°†åªèƒ½ä½¿ç”¨åŠŸèƒ½å—é™çš„æœ¬åœ°æ¨¡å‹)",
                                        parent=self.root)
             if key and key.startswith("sk-"):
                 CLOUD_API_KEY = key.strip()
                 print(f"Debug: API Key set via Dialog.")
        
        # çŠ¶æ€å˜é‡
        self.is_running = True
        self.current_detection = "None"
        self.llm_thinking = False
        self.analyzer = analyzer # åˆå§‹åŒ–ç”µè·¯åˆ†æå™¨å®ä¾‹
        
        # è¾“å…¥æºæ§åˆ¶
        self.input_source = "camera" # 'camera' æˆ– 'image'
        self.static_frame = None     # å­˜å‚¨åŠ è½½çš„é™æ€å›¾ç‰‡

        # æ ¡å‡†çŠ¶æ€
        self.calibration_requested = False
        
        # åˆå§‹åŒ–ç•Œé¢
        self.setup_ui()
        
        # åˆå§‹åŒ– AI å¼•æ“ (åå°åŠ è½½ï¼Œé˜²æ­¢å¡æ­»ç•Œé¢)
        self.log("æ­£åœ¨åˆå§‹åŒ– AI å¼•æ“ (YOLO + LLM)...")
        threading.Thread(target=self.load_models, daemon=True).start()
        
    def setup_ui(self):
        # å¸ƒå±€ï¼šå·¦è¾¹æ˜¯æ‘„åƒå¤´ï¼Œå³è¾¹æ˜¯æ§åˆ¶å°å’ŒèŠå¤©æ¡†
        main_pane = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_pane.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦ä¾§ï¼šè§†é¢‘åŒº
        left_frame = ttk.Frame(main_pane)
        main_pane.add(left_frame, weight=3)
        
        self.video_label = ttk.Label(left_frame, text="æ‘„åƒå¤´åˆå§‹åŒ–ä¸­...", background="black", foreground="white")
        self.video_label.pack(fill=tk.BOTH, expand=True)
        
        # å³ä¾§ï¼šäº¤äº’åŒº
        right_frame = ttk.Frame(main_pane)
        main_pane.add(right_frame, weight=1)
        
        # æ ‡é¢˜å’ŒçŠ¶æ€
        status_frame = ttk.Labelframe(right_frame, text="System Status")
        status_frame.pack(fill=tk.X, pady=5)
        
        self.status_label = ttk.Label(status_frame, text="Loading AI Models...", font=("Arial", 12, "bold"))
        self.status_label.pack(pady=10)
        
        self.detect_label = ttk.Label(status_frame, text="Current Object: None", font=("Arial", 10))
        self.detect_label.pack(pady=5)
        
        # èŠå¤©è®°å½•
        chat_frame = ttk.Labelframe(right_frame, text="AI Assistant Chat")
        chat_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        self.chat_history = scrolledtext.ScrolledText(chat_frame, wrap=tk.WORD, font=("Consolas", 10))
        self.chat_history.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.chat_history.insert(tk.END, "System: Welcome to LabGuardian.\n")
        self.chat_history.config(state=tk.DISABLED) # åªè¯»
        
        # æŒ‰é’®åŒº
        btn_frame = ttk.Frame(right_frame)
        btn_frame.pack(fill=tk.X, pady=5)
        
        # æ–°å¢ï¼šç”¨æˆ·è¾“å…¥æ¡†
        input_frame = ttk.Frame(btn_frame)
        input_frame.pack(fill=tk.X, pady=2)
        ttk.Label(input_frame, text="Ask:").pack(side=tk.LEFT)
        self.user_input = ttk.Entry(input_frame)
        self.user_input.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)
        self.user_input.bind("<Return>", lambda e: self.ask_ai_thread()) # å›è½¦å‘é€
        
        self.ask_btn = ttk.Button(btn_frame, text="ğŸ” Ask AI (Circuit Aware)", command=self.ask_ai_thread)
        self.ask_btn.pack(fill=tk.X, pady=5)
        
        # æ–°å¢ Calibration æŒ‰é’®
        calib_btn = ttk.Button(btn_frame, text="ğŸ“ Calibrate Camera", command=self.start_calibration)
        calib_btn.pack(fill=tk.X, pady=5)
        
        # æ–°å¢åŠ è½½å›¾ç‰‡æŒ‰é’®
        load_btn = ttk.Button(btn_frame, text="ğŸ“‚ Load Test Image", command=self.load_test_image)
        load_btn.pack(fill=tk.X, pady=5)
        
        # æ–°å¢æ˜¾ç¤ºç½‘è¡¨æŒ‰é’®
        netlist_btn = ttk.Button(btn_frame, text="ğŸ“ Show Circuit Netlist", command=self.show_netlist)
        netlist_btn.pack(fill=tk.X, pady=5)
        
        # æ–°å¢æ˜¾ç¤ºåŸç†å›¾æŒ‰é’®
        draw_btn = ttk.Button(btn_frame, text="ğŸ¨ Draw Schematic", command=self.draw_schematic)
        draw_btn.pack(fill=tk.X, pady=5)

        # --- Demo Controls (å®¹é”™æ§åˆ¶) ---
        ctrl_frame = ttk.Labelframe(btn_frame, text="Demo Controls")
        ctrl_frame.pack(fill=tk.X, pady=10)
        
        # 1. ç½®ä¿¡åº¦æ»‘å—
        ttk.Label(ctrl_frame, text="AI Sensitivity (Conf)").pack(anchor='w', padx=5)
        self.conf_slider = ttk.Scale(ctrl_frame, from_=0.01, to=0.99, orient=tk.HORIZONTAL)
        self.conf_slider.set(0.25) # é»˜è®¤å€¼
        self.conf_slider.pack(fill=tk.X, padx=5, pady=2)
        
        # 2. é‡ç½®æŒ‰é’®
        ttk.Button(ctrl_frame, text="ğŸ”„ Reset Circuit Analyzer", command=self.reset_analyzer).pack(fill=tk.X, pady=5)
        
        # --- Debug / Validation Zone ---
        debug_frame = ttk.Labelframe(btn_frame, text="Circuit Debugger")
        debug_frame.pack(fill=tk.X, pady=10)
        
        ttk.Button(debug_frame, text="â­ Set as Gold Ref", command=self.set_golden_ref).pack(fill=tk.X, pady=2)
        ttk.Button(debug_frame, text="âœ… Validate Current", command=self.validate_circuit).pack(fill=tk.X, pady=2)
        
        quit_btn = ttk.Button(btn_frame, text="Quit Application", command=self.close_app)
        quit_btn.pack(fill=tk.X)

    def reset_analyzer(self):
        if hasattr(self, 'analyzer'):
            self.analyzer.reset()
            self.log("ğŸ”„ Circuit Analyzer Reset. Cleared all connections.")
            
    def set_golden_ref(self):
        if hasattr(self, 'analyzer') and self.analyzer.components:
            validator.set_reference(self.analyzer)
            self.log("âœ… Current circuit saved as Golden Reference.")
            self.log(f"   (Components: {len(self.analyzer.components)})")
        else:
            self.log("âš ï¸ Analyzer empty, cannot set reference.")

    def validate_circuit(self):
        if hasattr(self, 'analyzer'):
            self.log("Running validation...")
            results = validator.compare(self.analyzer)
            self.log("--- Validation Report ---")
            for msg in results:
                self.log(msg)
            self.log("-----------------------")
        else:
            self.log("System not ready.")

    def show_netlist(self):
        if hasattr(self, 'analyzer'):
            netlist = self.analyzer.get_circuit_description()
            self.log("--- Generated Netlist ---")
            self.log(netlist)
            self.log("------------------------")
        else:
            self.log("System not ready or analyzer not initialized.")

    def draw_schematic(self):
        if hasattr(self, 'analyzer'):
            try:
                self.log("Generating Schematic...")
                # æ³¨æ„ï¼šMatplotlib ç»˜å›¾å¯èƒ½ä¼šé˜»å¡ GUIï¼Œè§†æƒ…å†µå¯èƒ½éœ€è¦ç‹¬ç«‹è¿›ç¨‹
                # ä½†è¿™é‡Œä½œä¸ºæ¼”ç¤ºå…ˆç›´æ¥è°ƒç”¨
                generator = SchematicGenerator(self.analyzer)
                generator.generate_schematic(show=True)
                self.log("âœ… Schematic Drawn.")
            except Exception as e:
                self.log(f"Schematic Error: {e}")
        else:
            self.log("System not ready.")

    def log(self, text):
        self.chat_history.config(state=tk.NORMAL)
        self.chat_history.insert(tk.END, f"[{datetime.now().strftime('%H:%M:%S')}] {text}\n")
        self.chat_history.see(tk.END)
        self.chat_history.config(state=tk.DISABLED)

    def load_models(self):
        try:
            # 1. åŠ è½½ YOLO
            self.status_label.config(text="Loading Vision Model...", foreground="orange")
            # å°è¯•åŠ è½½ä¸Šæ¬¡è®­ç»ƒçš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æ‰¾åˆ°åˆ™ç”¨é€šç”¨çš„
            try:
                self.yolo_model = YOLO(YOLO_MODEL_PATH) 
            except:
                self.log(f"Warning: Could not find {YOLO_MODEL_PATH}, using yolov8n.pt")
                self.yolo_model = YOLO("yolov8n.pt")
                
            self.log("âœ… Vision Model Loaded.")
            
            # 2. åŠ è½½ LLM
            self.status_label.config(text="Loading Language Model...", foreground="orange")
            
            if USE_CLOUD_LLM:
                if not CLOUD_API_KEY or "placeholder" in CLOUD_API_KEY:
                    self.log("âš ï¸ Cloud AI enabled but Key missing.")
                    self.log("Running in Vision-Only mode until Key is added.")
                    self.llm_client = None
                else:
                    try:
                        self.llm_client = OpenAI(api_key=CLOUD_API_KEY, base_url=CLOUD_BASE_URL)
                        self.log(f"âœ… Cloud AI Ready: {CLOUD_MODEL_NAME}")
                    except Exception as e:
                        self.log(f"Cloud AI Error: {e}")
                        self.llm_client = None
            else:
                # å…³é”®ä¿®æ”¹ï¼šæ­¤æ—¶ä¼ å…¥çš„æ˜¯ç»å¯¹è·¯å¾„ï¼Œæ‰€ä»¥ä¸ä¼šå†è¢«è¯¯åˆ¤ä¸º repo id
                self.llm_model = OVModelForCausalLM.from_pretrained(LLM_MODEL_PATH, device="GPU")
                self.tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH)
                self.log("âœ… Local Language Model Loaded.")
            
            self.status_label.config(text="System Ready - Active", foreground="green")
            
            # 3. å¼€å¯æ‘„åƒå¤´çº¿ç¨‹
            threading.Thread(target=self.video_loop, daemon=True).start()
            
        except Exception as e:
            self.log(f"Error loading models: {e}")
            self.status_label.config(text="System Error", foreground="red")

    def start_calibration(self):
        self.log("Starting calibration... Please click 4 corners in the popup window.")
        self.calibration_requested = True

    def load_test_image(self):
        file_path = filedialog.askopenfilename(title="Select Circuit Image", filetypes=[("Images", "*.jpg *.png *.jpeg *.bmp")])
        if file_path:
            img = cv2.imread(file_path)
            if img is not None:
                self.static_frame = img
                self.input_source = "image"
                self.log(f"Loaded image: {os.path.basename(file_path)}")
                self.status_label.config(text="Mode: Test Image", foreground="blue")
            else:
                self.log("Error: Failed to load image.")

    def video_loop(self):
        cap = cv2.VideoCapture(0)
        # é™ä½åˆ†è¾¨ç‡ä»¥æé«˜æ€§èƒ½
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        # æ ¡å‡†ç”¨çš„ä¸´æ—¶å˜é‡
        calib_points = []
        def mouse_callback(event, x, y, flags, param):
            # param æ˜¯å½“å‰çš„ç¼©æ”¾æ¯”ä¾‹ scale
            current_scale = param if param else 1.0
            
            # å·¦é”®ï¼šæ ¡å‡†é€‰ç‚¹
            if event == cv2.EVENT_LBUTTONDOWN and self.calibration_requested:
                real_x = int(x / current_scale)
                real_y = int(y / current_scale)
                calib_points.append([real_x, real_y])
                print(f"Calibration Point: {real_x}, {real_y}")
            
            # å³é”®ï¼šæ¼”ç¤ºæ•°æ®é‡‡é›† (è·å–å…ƒä»¶åæ ‡)
            elif event == cv2.EVENT_RBUTTONDOWN:
                real_x = int(x / current_scale)
                real_y = int(y / current_scale)
                # æ‰“å°å‡ºå¯ä»¥ç›´æ¥å¤åˆ¶åˆ°ä»£ç é‡Œçš„æ ¼å¼
                print(f"DEMO_DATA: [ {real_x}, {real_y}, {real_x+50}, {real_y+80} ] # Clicked Center")
                # åœ¨ç”»é¢ä¸Šç”»ä¸ªä¸´æ—¶çš„åœˆåé¦ˆä¸€ä¸‹
                cv2.circle(frame, (real_x, real_y), 5, (0, 0, 255), -1)
                cv2.imshow(win_name, frame)

        while self.is_running:
            # --- 1. è·å–æ¯ä¸€å¸§ ---
            if self.input_source == "image" and self.static_frame is not None:
                # ä½¿ç”¨åŠ è½½çš„é™æ€å›¾ç‰‡ï¼Œå¿…é¡» copy å¦åˆ™åç»­ç»˜å›¾ä¼šæ±¡æŸ“åŸå›¾
                frame = self.static_frame.copy()
                # ä¸ºäº†é˜²æ­¢é™æ€å›¾å¤ªå¤§æ’‘çˆ†å±å¹•ï¼Œå¯ä»¥ resize (å¯é€‰)
                # frame = cv2.resize(frame, (1024, 768)) 
                time.sleep(0.05) # é™æ€å›¾ä¸éœ€è¦é«˜é€Ÿåˆ·æ–°
            else:
                # ä½¿ç”¨æ‘„åƒå¤´
                ret, frame = cap.read()
                if not ret: break

            # --- æ ¡å‡†æ¨¡å¼ ---
            if self.calibration_requested:
                win_name = "Calibrate: Click 4 corners (TL->TR->BR->BL)"
                
                # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ŒåŒæ—¶é€‚åº”å±å¹•å®½å’Œé«˜
                h, w = frame.shape[:2]
                max_w = 1000
                max_h = 700
                
                scale_w = max_w / w
                scale_h = max_h / h
                scale = min(scale_w, scale_h, 1.0) # å–æœ€å°æ¯”ä¾‹ï¼Œä¸”ä¸æ”¾å¤§
                
                new_w = int(w * scale)
                new_h = int(h * scale)
                disp_frame = cv2.resize(frame, (new_w, new_h))
                
                cv2.namedWindow(win_name) 
                # ä¼ é€’ scale ç»™å›è°ƒ
                cv2.setMouseCallback(win_name, mouse_callback, param=scale)
                
                # ç»˜åˆ¶å·²é€‰ç‚¹ (éœ€è¦è½¬æ¢å›å±å¹•åæ ‡)
                draw_frame = disp_frame.copy()
                for i, p in enumerate(calib_points):
                    sx = int(p[0] * scale)
                    sy = int(p[1] * scale)
                    cv2.circle(draw_frame, (sx, sy), 5, (0, 0, 255), -1)
                    cv2.putText(draw_frame, str(i+1), (sx+10, sy), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

                cv2.imshow(win_name, draw_frame)
                cv2.waitKey(1)
                
                if len(calib_points) == 4:
                    import numpy as np
                    try:
                        # calib_points å­˜å‚¨çš„æ˜¯çœŸå®åæ ‡ï¼Œç›´æ¥ç”¨äºè®¡ç®—çŸ©é˜µ
                        src_pts = np.float32(calib_points)
                        board_map.get_perspective_matrix(src_pts)
                        self.log("âœ… Calibration successful! Board mapped.")
                        
                        # --- å¼¹çª—æ˜¾ç¤ºæ ¡å‡†åçš„æ•ˆæœ (å¸¦ç½‘æ ¼) ---
                        warped = board_map.apply_transform(frame)
                        
                        # ç»“æœçª—å£ä¹Ÿéœ€è¦ç¼©æ”¾æ˜¾ç¤º
                        h_w, w_w = warped.shape[:2]
                        # ç»“æœçª—å£åŒæ ·åº”ç”¨æœ€å¤§å®½é«˜é™åˆ¶
                        s_w = max_w / w_w
                        s_h = max_h / h_w
                        scale_res = min(s_w, s_h, 1.0)
                            
                        warped_disp = cv2.resize(warped, (int(w_w * scale_res), int(h_w * scale_res)))
                        h_wd, w_wd = warped_disp.shape[:2]
                        
                        # ç”»è¡Œçº¿ (Dynamic Rows)
                        rows_count = getattr(board_map, 'rows', 63)
                        for i in range(1, rows_count + 1): 
                            y = int(i * (h_wd / rows_count))
                            cv2.line(warped_disp, (0, y), (w_wd, y), (50, 50, 50), 1)
                            
                        cv2.imshow("Calibration Result (Press Any Key to Close)", warped_disp)
                        cv2.waitKey(0) # ç­‰å¾…æŒ‰é”®
                        try:
                            if cv2.getWindowProperty("Calibration Result (Press Any Key to Close)", cv2.WND_PROP_VISIBLE) >= 1:
                                cv2.destroyWindow("Calibration Result (Press Any Key to Close)")
                        except:
                            pass
                        
                    except Exception as e:
                        self.log(f"Calibration failed: {e}")
                    
                    try:
                        cv2.destroyWindow(win_name)
                    except:
                        pass
                    
                    self.calibration_requested = False
                    calib_points = [] # æ¸…ç©ºä»¥å¤‡ä¸‹æ¬¡ä½¿ç”¨
                continue # æš‚åœä¸»ç•Œé¢çš„æ›´æ–°ï¼Œä¸“æ³¨äºæ ¡å‡†çª—å£

            # YOLO æ¨ç†
            if hasattr(self, 'yolo_model'):
                # è·å–æ»‘å—çš„å½“å‰å€¼ä½œä¸ºåŠ¨æ€é˜ˆå€¼
                current_conf = 0.25
                if hasattr(self, 'conf_slider'):
                    current_conf = self.conf_slider.get()

                # ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è¿›è¡Œæ¨ç†
                results = self.yolo_model(frame, verbose=False, conf=current_conf) 
                annotated_frame = results[0].plot()

                # LOG detected objects for debugging
                if results[0].boxes:
                    det_info = [f"{results[0].names[int(b.cls[0])]}({float(b.conf[0]):.2f})" for b in results[0].boxes]
                    current_det_str = ",".join(det_info)
                    if not hasattr(self, 'last_det_log') or self.last_det_log != current_det_str:
                        print(f"DEBUG DETECT: {current_det_str}") 
                        self.last_det_log = current_det_str
                
                # --- æ–°å¢ Day 2 é€»è¾‘: å°†æ£€æµ‹æ¡†æ˜ å°„å›ç”µè·¯é€»è¾‘åæ ‡ (Advanced 2-Pin Logic) ---
                if hasattr(self, 'analyzer'):
                    self.analyzer = analyzer # ç¡®ä¿å¼•ç”¨çš„æ˜¯å…¨å±€å¯¼å…¥çš„é‚£ä¸ªå®ä¾‹ï¼Œæˆ–è€…åœ¨è¿™é‡Œå¤ä½
                    self.analyzer.reset() # æ¯ä¸€å¸§é‡æ–°æ„å»ºç”µè·¯å›¾

                if board_map.matrix is not None and results[0].boxes:
                    for box in results[0].boxes:
                        # è·å–è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        cls_id = int(box.cls[0])
                        label = results[0].names[cls_id]
                        
                        # --- æ ¸å¿ƒå‡çº§ï¼šå…ƒä»¶ç‰©ç†æŒ‡çº¹åº“ (Component Fingerprint Logic) ---
                        w = x2 - x1
                        h = y2 - y1
                        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                        
                        pin1_pixel, pin2_pixel = None, None
                        
                        # 1. è½´å‘å…ƒä»¶ (Axial): ç”µé˜»ã€äºŒæç®¡ã€å¯¼çº¿
                        # ç‰¹ç‚¹ï¼šå¼•è„šä½äºé•¿è½´çš„ä¸¤ç«¯ï¼Œåƒå“‘é“ƒä¸€æ ·
                        if label in ["Wire", "RESISTOR", "DIODE", "Resistor"]: 
                            if w > h: # æ¨ªå‘æ‘†æ”¾
                                margin = w * 0.05 # 5% çš„è¾¹ç¼˜å†…ç¼©ï¼Œæ›´ç²¾ç¡®
                                pin1_pixel = (x1 + margin, cy)
                                pin2_pixel = (x2 - margin, cy)
                            else: # çºµå‘æ‘†æ”¾
                                margin = h * 0.05
                                pin1_pixel = (cx, y1 + margin)
                                pin2_pixel = (cx, y2 - margin)
                                
                        # 2. å¾„å‘/ç›´æ’å…ƒä»¶ (Radial): LED, ç”µå®¹
                        # ç‰¹ç‚¹ï¼šå¼•è„šé€šå¸¸éƒ½åœ¨åº•éƒ¨ï¼Œä½†åœ¨ä¿¯è§†å›¾ä¸­ï¼Œå®ƒä»¬å¾€å¾€è·¨è¶Š 1-2 ä¸ªå­”
                        # æˆ‘ä»¬å‡è®¾å®ƒä»¬å‚ç›´äºé¢åŒ…æ¿æ’å…¥
                        elif label in ["LED", "CAPACITOR"]:
                            # å³ä½¿æ˜¯åœ†å½¢çš„LEDï¼Œæˆ‘ä»¬ä¹Ÿå°è¯•å¯»æ‰¾å®ƒçš„é•¿è½´æ–¹å‘æ¥ç¡®å®šå¼•è„šåˆ†å¸ƒ
                            if h > w: # ä¸»è¦æ˜¯çºµå‘
                                offset = h * 0.25 # å¼•è„šä¸åƒç”µé˜»é‚£æ ·åœ¨æœ€è¾¹ç¼˜
                                pin1_pixel = (cx, y1 + offset)
                                pin2_pixel = (cx, y2 - offset)
                            else: # ä¸»è¦æ˜¯æ¨ªå‘
                                offset = w * 0.25
                                pin1_pixel = (cx - offset, cy)
                                pin2_pixel = (cx + offset, cy)
                                
                        # 3. å°è£…å…ƒä»¶ (Package): æŒ‰é’®
                        # ç‰¹ç‚¹ï¼šå››è„šæ–¹å—ã€‚å¯¹äºç”µè·¯é€»è¾‘ï¼Œæˆ‘ä»¬å…³æ³¨å®ƒæ˜¯å¦è·¨æ¥äº†ä¸åŒçš„ Netã€‚
                        # é€šå¸¸æŒ‰é’®ä¼šè·¨æ¥ä¸­é—´çš„æ²Ÿæ§½ï¼Œæˆ–è€…è¿æ¥éè¿é€šçš„è¡Œã€‚
                        # æˆ‘ä»¬å–å…¶ç‰©ç†ä¸Šçš„â€œä¸Šè¾¹ç¼˜ä¸­å¿ƒâ€å’Œâ€œä¸‹è¾¹ç¼˜ä¸­å¿ƒâ€ä½œä¸ºç­‰æ•ˆå¼•è„šã€‚
                        elif "Button" in label:
                            margin = h * 0.15
                            pin1_pixel = (cx, y1 + margin)
                            pin2_pixel = (cx, y2 - margin)
                            
                        # 4. é»˜è®¤å›é€€é€»è¾‘
                        else:
                            if w > h:
                                pin1_pixel = (x1 + w*0.1, cy)
                                pin2_pixel = (x2 - w*0.1, cy)
                            else:
                                pin1_pixel = (cx, y1 + h*0.1)
                                pin2_pixel = (cx, y2 - h*0.1)

                        # å®šä¹‰å˜æ¢å‡½æ•° (Pixel -> Warped -> Logic)
                        def get_logic_loc(px, py):
                            src_point = np.array([[[px, py]]], dtype=np.float32)
                            dst_point = cv2.perspectiveTransform(src_point, board_map.matrix)
                            wx, wy = dst_point[0][0]
                            return board_map.pixel_to_logic(wx, wy)

                        loc1 = get_logic_loc(*pin1_pixel)
                        loc2 = get_logic_loc(*pin2_pixel)
                        
                        # å¦‚æœä¸¤ä¸ªå¼•è„šéƒ½åœ¨æœ‰æ•ˆåŒºåŸŸ
                        if loc1 and loc2 and loc1[0] != "Groove" and loc2[0] != "Groove":
                            # æ·»åŠ åˆ°ç”µè·¯åˆ†æå™¨
                            comp = CircuitComponent(f"{label}", label, loc1, loc2)
                            self.analyzer.add_component(comp)
                            
                            # ç»˜åˆ¶ "è™šæ‹Ÿè¿æ¥" (ç»¿è‰²çº¿æ¡ä»£è¡¨ç³»ç»Ÿè®¤ä¸ºå®ƒä»¬å·²è¿æ¥)
                            cv2.line(annotated_frame, (int(pin1_pixel[0]), int(pin1_pixel[1])), 
                                     (int(pin2_pixel[0]), int(pin2_pixel[1])), (0, 255, 0), 2)
                            
                            # æ˜¾ç¤ºå¼•è„šåŠå…¶æ‰€åœ¨çš„è¡Œå·
                            cv2.circle(annotated_frame, (int(pin1_pixel[0]), int(pin1_pixel[1])), 4, (255, 0, 0), -1)
                            cv2.circle(annotated_frame, (int(pin2_pixel[0]), int(pin2_pixel[1])), 4, (0, 0, 255), -1)
                            
                            # æ–‡å­—æ ‡æ³¨: "R1: 15-20"
                            info = f"{loc1[0]}-{loc2[0]}"
                            cv2.putText(annotated_frame, info, (int(x1), int(y1)-5), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

                    # --- åˆ†æå½“å‰ç”µè·¯å¹¶æ˜¾ç¤ºç®€æŠ¥ ---
                    try:
                         # ç®€å•çš„æ˜¾ç¤ºè¿é€šç»„æ•°
                        connected_nets = list(nx.connected_components(self.analyzer.graph))
                        status_text = f"Nets Found: {len(connected_nets)}"
                        cv2.putText(annotated_frame, status_text, (20, 40), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
                                   
                        # (å¯é€‰) å¦‚æœæ£€æµ‹åˆ° Row10 å’Œ Row20 è¿é€šï¼Œæ˜¾ç¤ºå¤§å¤§çš„ "Success"
                        # è¿™æ˜¯æ¼”ç¤ºçš„ä¸€ä¸ª trick
                        if self.analyzer.validate_connection('10', '20'): # ç¤ºä¾‹æ£€æŸ¥
                             cv2.putText(annotated_frame, "Circuit Closed!", (20, 80), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

                    except Exception as e:
                        print(f"Analysis Error: {e}")


                # æ›´æ–°å½“å‰æ£€æµ‹åˆ°çš„ç‰©ä½“
                if results[0].boxes:
                    # è·å–ç½®ä¿¡åº¦æœ€é«˜çš„ç±»åˆ«
                    cls_id = int(results[0].boxes.cls[0])
                    obj_name = results[0].names[cls_id]
                    self.current_detection = obj_name
                else:
                    self.current_detection = "None"
                    
                # åœ¨ä¸»çº¿ç¨‹æ›´æ–°ç•Œé¢æ–‡æœ¬
                self.root.after(0, lambda: self.detect_label.config(text=f"Detected: {self.current_detection}"))
            else:
                annotated_frame = frame

            # è½¬æ¢é¢œè‰² BGR -> RGB ç”¨äº tkinter æ˜¾ç¤º
            cv_image = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(cv_image)
            
            # ç¼©æ”¾å›¾ç‰‡ä»¥é€‚åº”å·¦ä¾§è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ (é˜²æ­¢å›¾ç‰‡è¿‡å¤§åªæ˜¾ç¤ºå±€éƒ¨)
            # è·å–å·¦ä¾§ Label çš„å½“å‰å¤§å°
            label_width = self.video_label.winfo_width()
            label_height = self.video_label.winfo_height()
            
            # å¦‚æœçª—å£åˆšå¯åŠ¨å°šæœªlayoutå®Œæˆï¼Œç»™ä¸€ä¸ªé»˜è®¤å€¼
            if label_width < 100: label_width = 800
            if label_height < 100: label_height = 600
            
            # ä¿æŒæ¯”ä¾‹ç¼©æ”¾
            pil_image.thumbnail((label_width, label_height), Image.Resampling.LANCZOS)
            
            tk_image = ImageTk.PhotoImage(image=pil_image)
            
            # æ›´æ–°è§†é¢‘ Label
            self.root.after(0, lambda img=tk_image: self.update_video_label(img))
            
            # ç¨å¾®ä¼‘çœ ï¼Œé‡Šæ”¾ CPU
            time.sleep(0.01)
            
        cap.release()

    def update_video_label(self, img):
        self.video_label.configure(image=img)
        self.video_label.image = img

    def ask_ai_thread(self):
        if self.llm_thinking:
            return
            
        # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
        custom_q = self.user_input.get().strip()
        if custom_q:
             self.user_input.delete(0, tk.END) # æ¸…ç©ºè¾“å…¥æ¡†
             threading.Thread(target=self.process_question, args=(self.current_detection, custom_q), daemon=True).start()
        elif self.current_detection != "None":
             threading.Thread(target=self.process_question, args=(self.current_detection, None), daemon=True).start()
        else:
             self.log("System: No object detected and no question typed.")

    def process_question(self, obj_name, custom_question=None):
        self.llm_thinking = True
        self.ask_btn.state(["disabled"])
        
        # 1. è·å–ç”µè·¯æ‹“æ‰‘æè¿°
        circuit_context = ""
        if hasattr(self, 'analyzer'):
            circuit_context = self.analyzer.get_circuit_description()
        
        # 2. æ„é€  Prompt (ä¸­æ–‡ä¼˜åŒ–)
        if custom_question:
            question = custom_question
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå­å®éªŒå®¤åŠ©æ‰‹ã€‚
ä½ æ‹¥æœ‰è®¡ç®—æœºè§†è§‰ç³»ç»Ÿæä¾›çš„å®æ—¶ç”µè·¯ç½‘è¡¨æ•°æ®ï¼š
{circuit_context}

è¯·åŸºäºæ­¤ç”µè·¯çŠ¶æ€å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
- å¦‚æœè¢«é—®åŠè¿æ¥ï¼Œè¯·æ ¹æ® Net (ç½‘ç»œ) ä¿¡æ¯åˆ¤æ–­ã€‚
- Push_Button = æŒ‰é’®å¼€å…³, Wire = å¯¼çº¿ã€‚
- è¯·ç”¨**ä¸­æ–‡**å›ç­”ï¼Œåƒä¸€ä¸ªäººç±»åŠ©æ•™ä¸€æ ·è‡ªç„¶ã€‚"""
        else:
            # é»˜è®¤é—®é¢˜
            question = f"æˆ‘æ­£åœ¨çœ‹ä¸€ä¸ª {obj_name}ï¼Œè¯·å‘Šè¯‰æˆ‘å®ƒåœ¨è¿™ä¸ªç”µè·¯ä¸­æ˜¯æ€ä¹ˆè¿æ¥çš„ï¼Ÿ"
            system_prompt = f"ä½ æ˜¯ä¸€ä¸ªå®éªŒå®¤åŠ©æ‰‹ã€‚å½“å‰ç”µè·¯è¿æ¥å¦‚ä¸‹ï¼š\n{circuit_context}\nè¯·ç”¨ä¸­æ–‡ç®€è¦æè¿° {obj_name} çš„è¿æ¥æƒ…å†µã€‚"
        
        self.log(f"User: {question}")
        self.log("AI: æ­£åœ¨æ€è€ƒ..." if USE_CLOUD_LLM else "AI: Local Thinking...")
        
        try:
            if USE_CLOUD_LLM and hasattr(self, 'llm_client') and self.llm_client:
                # --- Cloud AI è°ƒç”¨ ---
                response = self.llm_client.chat.completions.create(
                    model=CLOUD_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": question}
                    ],
                    max_tokens=300,
                    temperature=0.7
                )
                final_answer = response.choices[0].message.content.strip()
                self.log(f"AI: {final_answer}")
            
            elif hasattr(self, 'llm_model'):
                # --- Local AI è°ƒç”¨ (Fallback) ---
                # æ„é€ è¾“å…¥ (è‹±æ–‡ Prompt ä»¥ä¿è¯ TinyLlama æ•ˆæœ)
                messages = [
                    {"role": "system", "content": "You are a helpful lab assistant. Answer based on the circuit netlist provided."},
                    {"role": "user", "content": f"Context: {circuit_context}\nQuestion: {question}"},
                ]
                input_text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
                input_ids = self.tokenizer(input_text, return_tensors="pt").input_ids.to(self.llm_model.device)
                
                output = self.llm_model.generate(input_ids, max_new_tokens=100, temperature=0.7)
                answer = self.tokenizer.decode(output[0], skip_special_tokens=True)
                final_answer = answer.split("<|assistant|>")[-1].strip()
                self.log(f"AI (Local): {final_answer}")
            else:
                self.log("AI Error: No model available.")
                
        except Exception as e:
            self.log(f"Error generating answer: {e}")
            
        self.llm_thinking = False
        self.root.after(0, lambda: self.ask_btn.state(["!disabled"]))

    def close_app(self):
        self.is_running = False
        self.root.destroy()
        sys.exit()

if __name__ == "__main__":
    root = tk.Tk()
    app = LabGuardianApp(root)
    root.mainloop()
